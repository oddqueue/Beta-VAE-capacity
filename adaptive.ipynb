{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adaptive.ipynb","provenance":[],"collapsed_sections":["JGYjlePtNo-y","AeDUq-fhOIkE","27BImT-XOPbh","0ocdsNzJOUTh","eLJ6VxAYOYn2","lPHPwojmObnA","TXB_asKWBuHO"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"62db0a2e097a469699c778c6ce335fde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9db07e252dcb46e88075c1a9a1c231cc","IPY_MODEL_8bf8a524fd9f4bb49bb11e84934611a1","IPY_MODEL_d2ce514288e04c24acc9653a12f098d6"],"layout":"IPY_MODEL_16d7e432c46443a2a7f1457dcb3631b1"}},"9db07e252dcb46e88075c1a9a1c231cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c5776909ad49c2ba5cb6a7262034f6","placeholder":"​","style":"IPY_MODEL_02665d3a221a41e3a789c52193306d41","value":"100%"}},"8bf8a524fd9f4bb49bb11e84934611a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90387484d0104c5aa3c9319850554a14","max":1500000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c0f813b6986463da99119af68609b10","value":1500000}},"d2ce514288e04c24acc9653a12f098d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a7582c37424e69ad48e4319222d9fb","placeholder":"​","style":"IPY_MODEL_78bc1d07ef574d83a2d9409084b1d62e","value":" 1500000/1500000 [12:51:26&lt;00:00, 29.03it/s]"}},"16d7e432c46443a2a7f1457dcb3631b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38c5776909ad49c2ba5cb6a7262034f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02665d3a221a41e3a789c52193306d41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90387484d0104c5aa3c9319850554a14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c0f813b6986463da99119af68609b10":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28a7582c37424e69ad48e4319222d9fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78bc1d07ef574d83a2d9409084b1d62e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8TCtT7UpY-B","outputId":"2e1f21a7-28d3-48ea-e0f2-6b42e4716347","executionInfo":{"status":"ok","timestamp":1654448172599,"user_tz":-540,"elapsed":20251,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os \n","\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/project2\")"],"metadata":{"id":"aymSEbH1l_Y_","executionInfo":{"status":"ok","timestamp":1654448172600,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Import Modules"],"metadata":{"id":"JGYjlePtNo-y"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","import math\n","\n","from math import exp\n","from tqdm.auto import tqdm\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","from torchvision.utils import make_grid"],"metadata":{"id":"4Ow5coWyonOE","executionInfo":{"status":"ok","timestamp":1654448176527,"user_tz":-540,"elapsed":3930,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"id":"AeDUq-fhOIkE"}},{"cell_type":"code","source":["ROOT = os.getcwd()\n","\n","class Config:\n","    seed = 42\n","    device = \"cuda\"if torch.cuda.is_available() else 'cpu'\n","\n","    max_iter = 1500000\n","    batch_size = 64\n","\n","    C_max = 16\n","\n","    lr = 1e-4\n","    beta1 = 0.5\n","    beta2 = 0.999\n","\n","    s_beta1 = 0.5\n","\n","    log_dir = os.path.join(ROOT, \"log\")\n","    ckpt_dir = os.path.join(ROOT, \"checkpoint\")\n","    save_step = 250000\n","\n","if not os.path.exists(Config.log_dir):  \n","    os.makedirs(Config.log_dir)\n","\n","if not os.path.exists(Config.ckpt_dir):  \n","    os.makedirs(Config.ckpt_dir)\n","\n","print(Config.device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hY-a7vZH6Q7z","executionInfo":{"status":"ok","timestamp":1654448176945,"user_tz":-540,"elapsed":420,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"466d1831-1381-4a78-d0fb-d0d3010efd51"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  \n","    torch.backends.cudnn.deterministic = True  \n","    torch.backends.cudnn.benchmark = True \n","\n","seed_everything(Config.seed)"],"metadata":{"id":"9SHraia0slGo","executionInfo":{"status":"ok","timestamp":1654448176945,"user_tz":-540,"elapsed":5,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"27BImT-XOPbh"}},{"cell_type":"code","source":["!git clone https://github.com/YannDubs/disentangling-vae.git"],"metadata":{"id":"wciGqGmpHumm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654448176945,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"48ab8106-3199-4985-ec7f-474d45d7bc48"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'disentangling-vae' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["os.chdir(os.path.join(ROOT, \"disentangling-vae\"))\n","\n","from utils import datasets\n","from utils.viz_helpers import get_samples\n","\n","train_loader = datasets.get_dataloaders(\"dsprites\", batch_size=Config.batch_size)"],"metadata":{"id":"aE0aFHAdN9PY","executionInfo":{"status":"ok","timestamp":1654448193155,"user_tz":-540,"elapsed":16212,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"0ocdsNzJOUTh"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"X0RJLXdt_PcE","executionInfo":{"status":"ok","timestamp":1654448193617,"user_tz":-540,"elapsed":464,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"outputs":[],"source":["class View(nn.Module):\n","    def __init__(self, size):\n","        super(View, self).__init__()\n","        self.size = size\n","\n","    def forward(self, tensor):\n","        return tensor.view(self.size)\n","\n","class Encoder(nn.Module):\n","      def __init__(self, latent_dim, nc):\n","          super(Encoder, self).__init__()\n","          self.latent_dim = latent_dim\n","          self.nc = nc\n","          self.net = nn.Sequential(\n","              nn.Conv2d(nc, 32, 4, 2, 1),\n","              nn.ReLU(True),\n","              nn.Conv2d(32, 32, 4, 2, 1),\n","              nn.ReLU(True),\n","              nn.Conv2d(32, 64, 4, 2, 1),\n","              nn.ReLU(True),\n","              nn.Conv2d(64, 64, 4, 2, 1),\n","              nn.ReLU(True),\n","              nn.Conv2d(64, 256, 4, 1),\n","              nn.ReLU(True),\n","              View((-1, 256*1*1)),\n","              nn.Linear(256, latent_dim*2),\n","          )\n","          self.weight_init()\n","\n","      def weight_init(self):\n","          for block in self._modules:\n","              for m in self._modules[block]:\n","                  if isinstance(m, (nn.Linear, nn.Conv2d)):\n","                      init.kaiming_normal_(m.weight, nonlinearity='relu')\n","\n","      def forward(self, x):\n","          distributions = self.net(x)\n","          mu = distributions[:, :self.latent_dim]\n","          logvar = distributions[:, self.latent_dim:]\n","\n","          return mu, logvar\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_dim, nc):\n","        super(Decoder, self).__init__()\n","        self.latent_dim = latent_dim\n","        self.nc = nc\n","        self.net = nn.Sequential(\n","            nn.Linear(latent_dim, 256),\n","            View((-1, 256, 1, 1)),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(256, 64, 4),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 64, 4, 2, 1),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 32, 4, 2, 1),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, nc, 4, 2, 1),\n","        )\n","\n","        self.weight_init()\n","\n","    def weight_init(self):\n","        for block in self._modules:\n","            for m in self._modules[block]:\n","                if isinstance(m, (nn.Linear, nn.ConvTranspose2d)):\n","                    init.kaiming_normal_(m.weight, nonlinearity='relu')\n","\n","    def forward(self, z):\n","        x_recon = self.net(z)\n","\n","        return x_recon\n","\n","\n","class BetaVAE(nn.Module):\n","\n","    def __init__(self, latent_dim=10):\n","        super(BetaVAE, self).__init__()\n","        self.latent_dim = latent_dim\n","        self.img_size = (1, 64, 64)\n","        self.num_pixels = self.img_size[1] * self.img_size[2]\n","\n","        self.encoder = Encoder(latent_dim, self.img_size[0])\n","        self.decoder = Decoder(latent_dim, self.img_size[0])\n","\n","    def forward(self, x):\n","        mu, logvar = self.encoder(x)\n","        z = self.reparameterize(mu, logvar)\n","        x_recon = self.decoder(z)\n","\n","        return x_recon, mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        std = logvar.div(2).exp()\n","        eps = Variable(std.data.new(std.size()).normal_())\n","        return mu + std*eps"]},{"cell_type":"code","source":["model = BetaVAE().to(Config.device)\n","optimizer = optim.Adam(model.parameters(), lr=Config.lr, betas=(Config.beta1, Config.beta2))\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbRwgwwRAQxi","executionInfo":{"status":"ok","timestamp":1654448204840,"user_tz":-540,"elapsed":11225,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"0ef37a93-b473-4e44-f597-9077303a4aa2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["BetaVAE(\n","  (encoder): Encoder(\n","    (net): Sequential(\n","      (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (3): ReLU(inplace=True)\n","      (4): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (7): ReLU(inplace=True)\n","      (8): Conv2d(64, 256, kernel_size=(4, 4), stride=(1, 1))\n","      (9): ReLU(inplace=True)\n","      (10): View()\n","      (11): Linear(in_features=256, out_features=20, bias=True)\n","    )\n","  )\n","  (decoder): Decoder(\n","    (net): Sequential(\n","      (0): Linear(in_features=10, out_features=256, bias=True)\n","      (1): View()\n","      (2): ReLU(inplace=True)\n","      (3): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(1, 1))\n","      (4): ReLU(inplace=True)\n","      (5): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (6): ReLU(inplace=True)\n","      (7): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (8): ReLU(inplace=True)\n","      (9): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (10): ReLU(inplace=True)\n","      (11): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    )\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["## Objective"],"metadata":{"id":"eLJ6VxAYOYn2"}},{"cell_type":"code","source":["class PIDControl():\n","    def __init__(self):\n","        self.I_k1 = 0.0\n","        self.W_k1 = 1.0\n","        self.e_k1 = 0.0\n","        \n","    def _Kp_fun(self, Err, scale=1):\n","        return 1.0/(1.0 + float(scale)*exp(Err))\n","        \n","    def pid(self, exp_KL, kl_divergence, Kp=0.01, Ki=-0.001, Kd=0.01):\n","        error_k = exp_KL - kl_divergence\n","        ## comput U as the control factor\n","        Pk = Kp * self._Kp_fun(error_k)+1\n","        Ik = self.I_k1 + Ki * error_k\n","        \n","        ## window up for integrator\n","        if self.W_k1 < 1:\n","            Ik = self.I_k1\n","            \n","        Wk = Pk + Ik\n","\n","        if Wk <= self.W_k1:\n","            inc_cap = True\n","        else:\n","            inc_cap = False\n","\n","        self.W_k1 = Wk\n","        self.I_k1 = Ik\n","        \n","        ## min and max value\n","        if Wk < 1:\n","            Wk = 1\n","        \n","        return Wk, inc_cap"],"metadata":{"id":"WVzm7NKyDygN","executionInfo":{"status":"ok","timestamp":1654448204840,"user_tz":-540,"elapsed":9,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def reconstruction_loss(x, x_recon):\n","    batch_size = x.size(0)\n","    assert batch_size != 0\n","    \n","    recon_loss = F.binary_cross_entropy_with_logits(x_recon, x, size_average=False).div(batch_size)\n","\n","    return recon_loss"],"metadata":{"id":"7HvcXshm7xh6","executionInfo":{"status":"ok","timestamp":1654448204840,"user_tz":-540,"elapsed":6,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def kl_divergence(mu, logvar):\n","    batch_size = mu.size(0)\n","    assert batch_size != 0\n","    \n","    if mu.data.ndimension() == 4:\n","        mu = mu.view(mu.size(0), mu.size(1))\n","    if logvar.data.ndimension() == 4:\n","        logvar = logvar.view(logvar.size(0), logvar.size(1))\n","\n","    klds = -0.5*(1 + logvar - mu.pow(2) - logvar.exp())\n","    total_kld = klds.sum(1).mean(0, True)\n","    dimension_wise_kld = klds.mean(0)\n","    mean_kld = klds.mean(1).mean(0, True)\n","\n","    return total_kld, dimension_wise_kld, mean_kld"],"metadata":{"id":"l0Km1Lfz7x_Q","executionInfo":{"status":"ok","timestamp":1654448204841,"user_tz":-540,"elapsed":7,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"lPHPwojmObnA"}},{"cell_type":"code","source":["def train(model, data_loader, optimizer, max_iter, C_max, device, log_dir, ckpt_dir, save_step):\n","    model.train()\n","\n","    out = False\n","    global_iter = 0;\n","   \n","    pbar = tqdm(total=max_iter)\n","    pbar.update(global_iter)\n","\n","    ## init PID control\n","    PID = PIDControl()\n","    C = 0.5\n","\n","    logs = pd.DataFrame(columns=[\"iter\", \"recons_loss\", \"total_kld\", \"C_t\", \"beta_t\"])\n","\n","    while not out:\n","        for _, (x, _) in enumerate(data_loader):\n","            global_iter += 1\n","            pbar.update(1)\n","\n","            x = Variable(x.to(device))\n","            x_recon, mu, logvar = model(x)\n","            recon_loss = reconstruction_loss(x, x_recon)\n","            total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)\n","\n","            ## dynamic pid\n","            beta, inc_cap = PID.pid(C, total_kld.item())\n","            beta_vae_loss = recon_loss + beta * total_kld\n","\n","            optimizer.zero_grad()\n","            beta_vae_loss.backward()\n","            optimizer.step()\n","            \n","            if global_iter%20 == 0:               \n","                log = pd.DataFrame({\"iter\":global_iter, \"recons_loss\":recon_loss.item(), \"total_kld\":total_kld.item(), \"C_t\":C, \"beta_t\":beta}, index = [0])\n","                logs = logs.append(log, ignore_index = True)\n","                logs.to_csv(os.path.join(log_dir, \"adaptive_log.csv\"))\n","\n","            if global_iter % save_step == 0:\n","                ckpt = os.path.join(ckpt_dir, \"adaptive_step_{}.pt\".format(global_iter))\n","                torch.save(model.state_dict(), ckpt)\n","                pbar.write('Saved checkpoint(iter:{})'.format(global_iter))\n","\n","            if (inc_cap == True) and (max_iter != global_iter):\n","                C_step_value = (C_max - C) / (max_iter - global_iter)\n","                C += C_step_value\n","\n","            if global_iter >= max_iter:\n","                out = True\n","                break\n","\n","    ckpt = os.path.join(ckpt_dir, \"adaptive_step_final.pt\")\n","    torch.save(model.state_dict(), ckpt)\n","    logs.to_csv(os.path.join(log_dir, \"adaptive_log.csv\"))\n","    pbar.write('Saved checkpoint(iter:final)')\n","\n","    pbar.write(\"[Training Finished]\")\n","    pbar.close()"],"metadata":{"id":"FsDnARpqFnsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(model, train_loader, optimizer, Config.max_iter, Config.C_max, Config.device, Config.log_dir, Config.ckpt_dir, Config.save_step)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239,"referenced_widgets":["62db0a2e097a469699c778c6ce335fde","9db07e252dcb46e88075c1a9a1c231cc","8bf8a524fd9f4bb49bb11e84934611a1","d2ce514288e04c24acc9653a12f098d6","16d7e432c46443a2a7f1457dcb3631b1","38c5776909ad49c2ba5cb6a7262034f6","02665d3a221a41e3a789c52193306d41","90387484d0104c5aa3c9319850554a14","2c0f813b6986463da99119af68609b10","28a7582c37424e69ad48e4319222d9fb","78bc1d07ef574d83a2d9409084b1d62e"]},"id":"Lap4f4-9-Xt5","executionInfo":{"status":"ok","timestamp":1653765090860,"user_tz":-540,"elapsed":46286520,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"a6069aae-e2ba-4e05-a15b-af8d618b7a78"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1500000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62db0a2e097a469699c778c6ce335fde"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["Saved checkpoint(iter:250000)\n","Saved checkpoint(iter:500000)\n","Saved checkpoint(iter:750000)\n","Saved checkpoint(iter:1000000)\n","Saved checkpoint(iter:1250000)\n","Saved checkpoint(iter:1500000)\n","Saved checkpoint(iter:final)\n","[Training Finished]\n"]}]},{"cell_type":"markdown","source":["## MIG Score"],"metadata":{"id":"TXB_asKWBuHO"}},{"cell_type":"code","source":["def logsumexp(value, dim=None, keepdim=False):\n","    \"\"\"Numerically stable implementation of the operation\n","    value.exp().sum(dim, keepdim).log()\n","    \"\"\"\n","    if dim is not None:\n","        m, _ = torch.max(value, dim=dim, keepdim=True)\n","        value0 = value - m\n","        if keepdim is False:\n","            m = m.squeeze(dim)\n","        return m + torch.log(torch.sum(torch.exp(value0),\n","                                       dim=dim, keepdim=keepdim))\n","    else:\n","        m = torch.max(value)\n","        sum_exp = torch.sum(torch.exp(value - m))\n","        if isinstance(sum_exp, Number):\n","            return m + math.log(sum_exp)\n","        else:\n","            return m + torch.log(sum_exp)\n","\n","class Normal(nn.Module):\n","    def __init__(self, mu=0, sigma=1):\n","        super(Normal, self).__init__()\n","        self.normalization = Variable(torch.Tensor([np.log(2 * np.pi)]))\n","\n","        self.mu = Variable(torch.Tensor([mu]))\n","        self.logsigma = Variable(torch.Tensor([math.log(sigma)]))\n","\n","    def _check_inputs(self, size, mu_logsigma):\n","        if size is None and mu_logsigma is None:\n","            raise ValueError(\n","                'Either one of size or params should be provided.')\n","        elif size is not None and mu_logsigma is not None:\n","            mu = mu_logsigma.select(-1, 0).expand(size)\n","            logsigma = mu_logsigma.select(-1, 1).expand(size)\n","            return mu, logsigma\n","        elif size is not None:\n","            mu = self.mu.expand(size)\n","            logsigma = self.logsigma.expand(size)\n","            return mu, logsigma\n","        elif mu_logsigma is not None:\n","            mu = mu_logsigma.select(-1, 0)\n","            logsigma = mu_logsigma.select(-1, 1)\n","            return mu, logsigma\n","        else:\n","            raise ValueError(\n","                'Given invalid inputs: size={}, mu_logsigma={})'.format(\n","                    size, mu_logsigma))\n","\n","    def sample(self, size=None, params=None):\n","        mu, logsigma = self._check_inputs(size, params)\n","        std_z = Variable(torch.randn(mu.size()).type_as(mu.data))\n","        sample = std_z * torch.exp(logsigma) + mu\n","        return sample\n","\n","    def log_density(self, sample, params=None):\n","        if params is not None:\n","            mu, logsigma = self._check_inputs(None, params)\n","        else:\n","            mu, logsigma = self._check_inputs(sample.size(), None)\n","            mu = mu.type_as(sample)\n","            logsigma = logsigma.type_as(sample)\n","\n","        c = self.normalization.type_as(sample.data)\n","        inv_sigma = torch.exp(-logsigma)\n","        tmp = (sample - mu) * inv_sigma\n","        return -0.5 * (tmp * tmp + 2 * logsigma + c)\n","\n","    def NLL(self, params, sample_params=None):\n","        \"\"\"Analytically computes\n","            E_N(mu_2,sigma_2^2) [ - log N(mu_1, sigma_1^2) ]\n","        If mu_2, and sigma_2^2 are not provided, defaults to entropy.\n","        \"\"\"\n","        mu, logsigma = self._check_inputs(None, params)\n","        if sample_params is not None:\n","            sample_mu, sample_logsigma = self._check_inputs(None, sample_params)\n","        else:\n","            sample_mu, sample_logsigma = mu, logsigma\n","\n","        c = self.normalization.type_as(sample_mu.data)\n","        nll = logsigma.mul(-2).exp() * (sample_mu - mu).pow(2)             + torch.exp(sample_logsigma.mul(2) - logsigma.mul(2)) + 2 * logsigma + c\n","        return nll.mul(0.5)\n","\n","    def kld(self, params):\n","        \"\"\"Computes KL(q||p) where q is the given distribution and p\n","        is the standard Normal distribution.\n","        \"\"\"\n","        mu, logsigma = self._check_inputs(None, params)\n","        kld = logsigma.mul(2).add(1) - mu.pow(2) - logsigma.exp().pow(2)\n","        kld.mul_(-0.5)\n","        return kld\n","\n","    def get_params(self):\n","        return torch.cat([self.mu, self.logsigma])\n","\n","    @property\n","    def nparams(self):\n","        return 2\n","\n","    @property\n","    def ndim(self):\n","        return 1\n","\n","    @property\n","    def is_reparameterizable(self):\n","        return True\n","\n","    def __repr__(self):\n","        tmpstr = self.__class__.__name__ + ' ({:.3f}, {:.3f})'.format(\n","            self.mu.data[0], self.logsigma.exp().data[0])\n","        return tmpstr\n","\n","def estimate_entropies(qz_samples, qz_params, q_dist=Normal(), n_samples=10000, weights=None):\n","    \"\"\"Computes the term:\n","        E_{p(x)} E_{q(z|x)} [-log q(z)]\n","    and\n","        E_{p(x)} E_{q(z_j|x)} [-log q(z_j)]\n","    where q(z) = 1/N sum_n=1^N q(z|x_n).\n","    Assumes samples are from q(z|x) for *all* x in the dataset.\n","    Assumes that q(z|x) is factorial ie. q(z|x) = prod_j q(z_j|x).\n","    Computes numerically stable NLL:\n","        - log q(z) = log N - logsumexp_n=1^N log q(z|x_n)\n","    Inputs:\n","    -------\n","        qz_samples (K, N) Variable\n","        qz_params  (N, K, nparams) Variable\n","        weights (N) Variable\n","    \"\"\"\n","\n","    # Only take a sample subset of the samples\n","    if weights is None:\n","        qz_samples = qz_samples.index_select(1, Variable(torch.randperm(qz_samples.size(1))[:n_samples].cuda()))\n","    else:\n","        sample_inds = torch.multinomial(weights, n_samples, replacement=True)\n","        qz_samples = qz_samples.index_select(1, sample_inds)\n","\n","    K, S = qz_samples.size()\n","    N, _, nparams = qz_params.size()\n","    assert(nparams == q_dist.nparams)\n","    assert(K == qz_params.size(1))\n","\n","    if weights is None:\n","        weights = -math.log(N)\n","    else:\n","        weights = torch.log(weights.view(N, 1, 1) / weights.sum())\n","\n","    entropies = torch.zeros(K).cuda()\n","\n","    k = 0\n","    while k < S:\n","        batch_size = min(10, S - k)\n","        logqz_i = q_dist.log_density(\n","            qz_samples.view(1, K, S).expand(N, K, S)[:, :, k:k + batch_size],\n","            qz_params.view(N, K, 1, nparams).expand(N, K, S, nparams)[:, :, k:k + batch_size])\n","        k += batch_size\n","\n","        # computes - log q(z_i) summed over minibatch\n","        entropies += - logsumexp(logqz_i + weights, dim=0, keepdim=False).data.sum(1)\n","\n","    entropies /= S\n","\n","    return entropies\n","\n","\n","def MIG(mi_normed):\n","    return torch.mean(mi_normed[:, 0] - mi_normed[:, 1])\n","\n","def compute_metric_shapes(marginal_entropies, cond_entropies):\n","    factor_entropies = [6, 40, 32, 32]\n","    mutual_infos = marginal_entropies[None] - cond_entropies\n","    mutual_infos = torch.sort(mutual_infos, dim=1, descending=True)[0].clamp(min=0)\n","    mi_normed = mutual_infos / torch.Tensor(factor_entropies).log()[:, None]\n","    metric = MIG(mi_normed)\n","    return metric"],"metadata":{"id":"CEmPO6n_PRFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BetaVAE().to(Config.device)\n","model.load_state_dict(torch.load(os.path.join(Config.ckpt_dir, \"adaptive_step_final.pt\")))\n","model.eval()\n","\n","test_loader = datasets.get_dataloaders(\"dsprites\", batch_size=Config.batch_size, shuffle=False)\n","q_dist = Normal()\n","N = len(test_loader.dataset)  \n","K = model.latent_dim             \n","nparams = q_dist.nparams\n","\n","print('Computing q(z|x) distributions.')\n","qz_params = torch.Tensor(N, K, nparams)\n","\n","n = 0\n","for i, (x, _) in enumerate(test_loader):\n","    print(i + 1, len(test_loader), end='\\r')\n","    batch_size = x.size(0)\n","    qz_params[n:n + batch_size] = model.encoder.net.forward(x.cuda()).view(batch_size, nparams, model.latent_dim).transpose(1, 2).data\n","\n","    n += batch_size\n","\n","qz_params = Variable(qz_params.view(3, 6, 40, 32, 32, K, nparams).cuda())\n","qz_params[:,:,:,:,:,:,1] = qz_params[:,:,:,:,:,:,1]/2 \n","qz_samples = q_dist.sample(params=qz_params)\n","\n","print('Estimating marginal entropies.')\n","\n","marginal_entropies = estimate_entropies(\n","    qz_samples.view(N, K).transpose(0, 1),\n","    qz_params.view(N, K, nparams),\n","    q_dist)\n","\n","marginal_entropies = marginal_entropies.cpu()\n","cond_entropies = torch.zeros(4, K)\n","\n","print('Estimating conditional entropies for scale.')\n","for i in range(6):\n","    qz_samples_scale = qz_samples[:, i, :, :, :, :].contiguous()\n","    qz_params_scale = qz_params[:, i, :, :, :, :].contiguous()\n","\n","    cond_entropies_i = estimate_entropies(\n","        qz_samples_scale.view(N // 6, K).transpose(0, 1),\n","        qz_params_scale.view(N // 6, K, nparams),\n","        q_dist)\n","\n","    cond_entropies[0] += cond_entropies_i.cpu() / 6\n","\n","print('Estimating conditional entropies for orientation.')\n","for i in range(40):\n","    qz_samples_scale = qz_samples[:, :, i, :, :, :].contiguous()\n","    qz_params_scale = qz_params[:, :, i, :, :, :].contiguous()\n","\n","    cond_entropies_i = estimate_entropies(\n","        qz_samples_scale.view(N // 40, K).transpose(0, 1),\n","        qz_params_scale.view(N // 40, K, nparams),\n","        q_dist)\n","\n","    cond_entropies[1] += cond_entropies_i.cpu() / 40\n","\n","print('Estimating conditional entropies for pos x.')\n","for i in range(32):\n","    qz_samples_scale = qz_samples[:, :, :, i, :, :].contiguous()\n","    qz_params_scale = qz_params[:, :, :, i, :, :].contiguous()\n","\n","    cond_entropies_i = estimate_entropies(\n","        qz_samples_scale.view(N // 32, K).transpose(0, 1),\n","        qz_params_scale.view(N // 32, K, nparams),\n","        q_dist)\n","\n","    cond_entropies[2] += cond_entropies_i.cpu() / 32\n","\n","print('Estimating conditional entropies for pox y.')\n","for i in range(32):\n","    qz_samples_scale = qz_samples[:, :, :, :, i, :].contiguous()\n","    qz_params_scale = qz_params[:, :, :, :, i, :].contiguous()\n","\n","    cond_entropies_i = estimate_entropies(\n","        qz_samples_scale.view(N // 32, K).transpose(0, 1),\n","        qz_params_scale.view(N // 32, K, nparams),\n","        q_dist)\n","\n","    cond_entropies[3] += cond_entropies_i.cpu() / 32\n","\n","metric = compute_metric_shapes(marginal_entropies, cond_entropies)\n","\n","print()\n","print('MIG: {}'.format(metric.cpu().numpy()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9pXY67uZaPA","executionInfo":{"status":"ok","timestamp":1653765286893,"user_tz":-540,"elapsed":195625,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"02f7dd87-d94d-482b-fd33-19637685701f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing q(z|x) distributions.\n","Estimating marginal entropies.\n","Estimating conditional entropies for scale.\n","Estimating conditional entropies for orientation.\n","Estimating conditional entropies for pos x.\n","Estimating conditional entropies for pox y.\n","\n","MIG: 0.5273207426071167\n"]}]},{"cell_type":"markdown","source":["## Reconstruction & Latent Traversal"],"metadata":{"id":"B-1Z3uFQOkrt"}},{"cell_type":"code","source":["def reconstruct(model, upsample_factor, data, size):\n","    n_samples = size[0] // 2 * size[1]\n","\n","    with torch.no_grad():\n","        originals = data.to(Config.device)[:n_samples, ...]\n","        recs, _, _ = model(originals)\n","\n","    originals = originals.cpu()\n","    recs = recs.view(-1, * model.img_size).cpu()\n","\n","    to_plot = torch.cat([originals, recs])\n","\n","    to_plot = F.interpolate(to_plot, scale_factor=upsample_factor)\n","    grid = make_grid(to_plot)\n","    img_grid = grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0)\n","    img_grid = img_grid.to('cpu', torch.uint8).numpy()\n","\n","    return img_grid\n","\n","def traverse(model, upsample_factor, n_per_latent, n_latents, max_traversal):\n","    latent_samples = [traverse_line(dim, n_latents, n_per_latent, max_traversal) for dim in range(n_latents)]\n","    latent_samples = torch.cat(latent_samples, dim=0).to(Config.device)\n","\n","    decoded_traversal = model.decoder(latent_samples).cpu()\n","    decoded_traversal = decoded_traversal[range(n_per_latent * n_latents), ...]\n","\n","    to_plot = F.interpolate(decoded_traversal.data, scale_factor=upsample_factor)\n","    grid = make_grid(to_plot)\n","    img_grid = grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0)\n","    img_grid = img_grid.to('cpu', torch.uint8).numpy()\n","\n","    return img_grid\n","        \n","def traverse_line(idx, latent_dim, n_samples, max_traversal):\n","    samples = torch.zeros(n_samples, latent_dim)\n","    traversals = torch.linspace(*(-1 * max_traversal, max_traversal), steps=n_samples)\n","\n","    for i in range(n_samples):\n","        samples[i, idx] = traversals[i]\n","\n","    return samples"],"metadata":{"id":"B-Q4Wt7z-5fI","executionInfo":{"status":"ok","timestamp":1654448204841,"user_tz":-540,"elapsed":6,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = BetaVAE().to(Config.device)\n","model.load_state_dict(torch.load(os.path.join(Config.ckpt_dir, \"adaptive_step_final.pt\")))\n","model.eval()\n","\n","samples = get_samples(\"dsprites\", 6 * 7)\n","n_latents = model.latent_dim\n","\n","reconstructions = reconstruct(model, 1, samples[:2 * 8, ...], (2, 8))\n","traversals = traverse(model, 1, 8, n_latents, 2)\n","\n","reconstructions = Image.fromarray(reconstructions)\n","traversals = Image.fromarray(traversals)\n","\n","reconstructions_name = os.path.join(Config.log_dir, \"adaptive_reconstruct.png\")\n","traversals_name = os.path.join(Config.log_dir, \"adaptive_traverse.png\")\n","\n","reconstructions.save(reconstructions_name)\n","traversals.save(traversals_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SXD8w9ga7IbG","executionInfo":{"status":"ok","timestamp":1654448337030,"user_tz":-540,"elapsed":11515,"user":{"displayName":"Sangkyu Lee","userId":"09682951002772598371"}},"outputId":"f6772fe0-a15f-465d-afc8-1cde76cc89a6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected idcs: [670487, 116739, 26225, 288389, 256787, 234053, 146316, 107473, 709570, 571858, 91161, 619176, 442417, 33326, 31244, 98246, 229258, 243962, 529903, 631262, 27824, 588508, 208496, 681453, 735392, 571412, 439898, 231148, 471029, 617889, 291704, 6814, 167414, 732052, 443143, 356778, 291369, 163032, 225772, 352944, 107175, 97251]\n"]}]}]}